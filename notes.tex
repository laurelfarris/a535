\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsmath}

\usepackage[usenames, dvipsnames]{color}
 
 \definecolor{mypink1}{rgb}{0.858, 0.188, 0.478}
 \definecolor{mypink2}{RGB}{219, 48, 122}
 \definecolor{mypink3}{cmyk}{0, 0.7808, 0.4429, 0.1412}
 \definecolor{mygray}{gray}{0.6}
  
%  \begin{document}
%  User-defined colours with different colour models:
%   
%   \begin{enumerate}
%   \item \textcolor{mypink1}{Pink with rgb}
%   \item \textcolor{mypink2}{Pink with RGB}
%   \item \textcolor{mypink3}{Pink with cmyk}
%   \item \textcolor{mygray}{Gray with gray}
%   \end{enumerate}



\setlength{\parindent}{0em}
\setlength{\parskip}{0.5em}

\title{ASTR 535 Lecture Notes}
\author{Jon Holtzman}
\date{Spring 2016}

\begin{document}
\maketitle

course website: \textcolor{blue}
{\url{http://astronomy.nmsu.edu/holtz/a535}}

\textcolor{magenta}{Friday, January 22}
\section*{Properties of light, magnitudes, errors, and error analysis}

\subsection*{Light}
Wavelength regimes:
\begin{itemize}
    \item gamma rays
    \item x-rays
    \item ultraviolent (UV)
        \begin{itemize}
            \item near: 900--3500 \AA{}
            \item far: 100--900 \AA{}
        \end{itemize}
        The 900 \AA{} break is because of the Lyman limit at 912 \AA{}.
        This is where neutral hydrogen is ionized, so the universe is largely
        opaque to wavelengths shorter than this.
    \item visual (V): 4000--7000 \AA{}
    (note that `V' is different from `optical',
        which is slightly broader: 3500--10000 \AA{}. The 3500 \AA{} cutoff
        is due to the Earth's atmosphere being opaque to wavelengths shorter
        than this).
    \item IR
        \begin{itemize}
            \item near: 1--5 $\mu$ (1--10 $\mu$ in online notes)
            \item mid: (10--100 $\mu$)
            \item far: 5--100 $\mu$ (100--1000 $\mu$)
        \end{itemize}
    \item sub-mm 500--1000 $\mu$
    \item microwave
    \item radio
\end{itemize}
Quantities of light:
\begin{itemize}
    \item Intensity $I(\theta,\phi)$ [erg s$^{-1}\ \nu^{-1}\ \Omega^{-1}$]:
        Encapsulates $direction$ light is coming from.
        Also known as radiance.
    \item Surface Brightness (SB)
        [erg s$^{-1}$ cm$^{-2}$ $\nu^{-1}$ sterradian$^{-1}$]:
        amount of energy $received$ in a unit surface
        element per unit time per unit frequency (or wavelength)
        from a unit
        solid angle in the direction ($\theta,\phi$), where $\theta$
        is the angle
        away from the normal to the surface element, and $\phi$ is the
        azimuthal angle.
        To calculate SB, just divide the flux by the angle subtended
        by the object [rad$^2$]. At a larger distance, the flux will
        be smaller, but so will the angle subtended by the object, so
        SB is independent of distance unless considering cosmological
        scales, where the curvature of spacetime has an effect.
    \item Flux (F) [erg s$^{-1}$ cm$^{-2}\ \nu^{-1}$]:
        amount of energy passing through a unit surface element
        in all directions, defined by
        \begin{equation}
            F_{\nu} = \int I_{\nu}\cos(\theta)\textrm{d}\Omega
        \end{equation}
        where d$\Omega$ is the solid angle element, and the integration is
        over the entire solid angle. The $\cos(\theta)$ factor is important
        for, e.g., ISM where light is coming from all directions, but for
        tiny objects, $\theta$ is negligibally small and can be dropped.
        Integrates over $all$ directions.
        Also known as irradiance.
    \item Luminosity (L) [erg s$^{-1}$]:
        $intrinsic$ energy emitted by the source per
        second ($\sim$ power). For an isotropically emitting source,
        \begin{equation}
            L = 4 \pi d^2 F
        \end{equation}
        where $d$ = distance to source (so L can only be calculated if
        the distance is known). Also known as radiant flux.
\end{itemize}
What to measure for sources:
\begin{itemize}
    \item Resolved: directly measure surface brightness (intensity)
        distribution on the sky, usually over some bandpass or wavelength
        interval.
    \item Unresolved: measure the flux. Diffraction is the reason stellar
        surfaces cannot be resolved. Because of this, we cannot measure
        SB, so we measure flux, integrated over the entire object.
\end{itemize}

Questions:
\begin{itemize}
    \item What are the dimensions of the three quantities: luminosity,
        surface brightness (intensity), and flux?
    \item How do the three quantities depend on distance to the source?
    \item To what quantity is apparent magnitude of a star related?
    \item To what quantity is the absolute magnitude related?
\end{itemize}
Amount of light emitted is a function of wavelength,
so we are often interested
in e.g.\ flux per unit wavelength (or frequency),
also known as $specific$ flux.
Using $\lambda=\frac{c}{\nu} \rightarrow
\frac{\textrm{d}\lambda}{\textrm{d}\nu} = \frac{-c}{\nu^2}$
\begin{align*}
    \int F_{\nu} \textrm{d} \nu &= -\int F_{\lambda} \textrm{d} \lambda\\
    F_{\nu} \textrm{d} \nu &= -F_{\lambda} \textrm{d} \lambda\\
    F_{\nu} &= -F_{\lambda} \frac{\textrm{d} \lambda}{\textrm{d}\nu}\\
    &= F_{\lambda} \frac{c}{\nu^2}\\
    &= F_{\lambda} \frac{\lambda^2}{c}\\
\end{align*}
The negative comes from frequency and wavelength increasing in
opposite directions.
Note that a constant $F_{\lambda}$ implies a $non$-constant $F_{\nu}$
and vice versa. Depending on where you are, a constant chunk of 1 Hz is
not the same wavelength range.

Units: often cgs, magnitudes, Jansky (a flux density unit
corresponding to 10$^{-26}$ W m$^{-2}$ Hz$^{-1}$)

There are often variations in terminology

Terminology of measurements:
\begin{itemize}
    \item photometry (broad-band flux measurement): SB or flux, integrated
        over some wavelength range.
    \item spectroscopy (\emph{relative} measurement of fluxes at
        different wavelengths):
        $f(\lambda)$
    \item spectrophotometry (\emph{absolute} measurement of fluxes at
        different wavelengths):
        $f(\lambda)$
    \item astrometry: concerned with positions of observed flux, not brightness,
        but direction.
    \item morphology: intensity as a function of position;
        often, absolute measurements are unimportant. Deals with $resolved$
        objects, intensity as function of position.
\end{itemize}
Generally, measure \emph{flux} with photometry, and flux
\emph{density} (per unit wavelength)  with spectroscopy
(down to the resolution of the spectrograph).
In practice, with most detectors,
we measure photon flux [photons cm$^{-2}$ s$^{-1}$]
with a photon counting device,
rather than energy flux (which is done with bolometers).
The monochromatic photon flux is given by the
energy flux ($F_{\lambda}$)
divided by the
energy per photon ($E_{photon} = \frac{hc}{\lambda}$), or
$$ \textrm{photon\ flux} = \int F_{\lambda}
    \frac{\lambda}{hc} \textrm{d} \lambda $$

% Magnitudes and photometric systems

\subsection*{Magnitudes and photometric systems}
Magnitudes are related to flux (and SB and L) by:
    $$    m_1 - m_2 = -2.5 \log \frac{b_1}{b_2} $$
or for a single object:
\begin{align*}
    m &= -2.5 \log \frac{F}{F_0}\\
      &= -2.5 \log F + 2.5 \log F_0
\end{align*}
where the coefficient of proportionality, $F_0$, depends on the definition
of photometric system; the quantity $2.5 \log F_0$ may be referred to as
the photometric system zeropoint. Note that this relationship holds
regardless of what photometric system you are using. Inverting, one gets:
    $$ F = F_0 \times 10^{-0.4\textrm{m}} $$
Just as fluxes can be represented in magnitude units, flux densities can be
specified by monochromatic magnitudes:
\begin{equation*}
    F_{\lambda} = F_0 (\lambda) \times 10^{-0.4 \textrm{m}(\lambda)}
\end{equation*}
although spectra are more often given in flux units than in magnitude units.
Note that it is possible that $F_0$ is a function of wavelength.

Since magnitudes are logarithmic, the $difference$ between
magnitudes corresponds to a ratio of fluxes; ratios of magnitudes are
generally unphysical. If one is just doing relative measurements of
brightness between objects, this can be done without knowledge of $F_0$
(or, equivalently, the system zeropoint); objects that differ in brightness
by $\Delta$M have the same ratio of brightness (10$^{-0.4 \Delta M}$)
regardless of what photometric system they are in.
\textcolor{red}{The photometric system
definitions and zeropoints are only needed when converting between calibrated
magnitudes and fluxes}. Note that this means that if one references the
brightness of one object relative to that of another, a magnitude system
can be set up relative to the brightness of the reference source. However, the
utility of a system when doing astrophysics generally requires an
understanding of the actual fluxes.\\

\noindent \textcolor{magenta}{Monday, January 25}\\

\noindent There are three main types of magnitude systems in use in astronomy:
STMAG, ABNU, and VEGAMAG.
We start by describing the two simpler ones: the STMAG and the ABNU mag system.
In these simple systems, the reference flux is just a constant value in
$F_{\lambda}$ or $F_{\nu}$. However, these are not always the most widely used
systems in astronomy, because
\textcolor{red}{no natural source exists with a flat spectrum}.\\

\noindent The STMAG (Space Telescope MAGnitude) is defined
relative to a source of constant $F_{\lambda}$. In this system,
the reference flux is given by
\begin{equation*}
    F_{0,\lambda} = 3.60 \times 10^{-9}\ \textrm{erg\ s}^{-1}\
    \textrm{cm}^{-2}\ \textrm{\AA{}}^{-1}
\end{equation*}
which is equal to the flux of Vega at 5500\AA{};
hence a star of Vega's brightness at 5500\AA{} is defined to have m=0.
Alternatively (using $m = -2.5\log \frac{F}{F_0}$), we can write
\begin{equation*}
    m_{\textrm{STMAG}} = -2.5 \log F_{\lambda} - 21.1
\end{equation*}
for $F_{\lambda}$ in \textcolor{red}{cgs units}.\\

\noindent The ABNU system is defined relative to a source
of constant $F_{\nu}$ and we have
\begin{equation*}
    F_{0,\nu} = 3.63 \times 10^{-20}\ \textrm{erg\ s}^{-1}\
    \textrm{cm}^{-2}\ \textrm{Hz}^{-1}
\end{equation*}
or
\begin{equation*}
    m_{\textrm{ABNU}} = -2.5 \log F_{\nu} - 48.6
\end{equation*}
for $F_{\nu}$ in \textcolor{red}{cgs units}.
Again, the constant comes from the flux of Vega.\\

\noindent Magnitudes usually refer to the flux integrated over a
spectral bandpass. In this case, $F$ and $F_0$ refer to fluxes
integrated over the bandpass.
\begin{align*}
    m_{\textrm{STMAG}} &= -2.5 \log \frac{\int F_{\lambda} \lambda
    \textrm{d}\lambda}{\int3.6\times10^{-9}\lambda\textrm{d}\lambda}\\
    m_{\textrm{ABNU}} &= -2.5 \log \frac{\int F_{\nu}\nu^{-1}
\textrm{d}\nu}{\int 3.6 \times 10^{-20}\nu^{-1}\textrm{d}\nu}
\end{align*}
These are defined to be the same at 5500\AA{}.
The factors of $\lambda$ and $\nu$ come from the conversion factor
$hc/\lambda$, where $h$ and $c$ cancel out in the
fractions in each equation.\\

\noindent Note that these systems differ by more than a constant,
because one is defined by units of $F_{\lambda}$ and the other by $F_{\nu}$,
so the difference betwen the systems is a function of wavelength.
(Question: what's the relations between $m_{STMAG}$ and $m_{ABNU}$?)\\

\noindent Note also that, using magnitudes,
\textcolor{red}{the measured magnitude is
nearly independent of bandpass width}, so a broader bandpass does not
imply a brighter (smaller) magnitude, which is not the case for
fluxes. The reference is being integrated as well, so they cancel.\\

\noindent The standard UBVRI broadband photometric system, as well as
several other magnitude systems, however, are not defined for a
constant (flat) $F_{\lambda}$ or $F_{\nu}$ spectrum; rather, they are defined
relative to the spectrum of an A0V star. Most systems are defined (or
at least were originally) to have the magnitude of Vega be zero in all
bandpasses (VEGAMAGS); if you ever get into this in detail, note that
this is not exactly true for the UBVRI system.\\

\noindent For the broadband UBVRI system, we have
\begin{equation*}
    m_{\textrm{UBVRI}} \approx -2.5 \log
    \frac{\int_{UBVRI}F_{\lambda}(object)\lambda\textrm{d}\lambda}
    {\int_{UBVRI}F_{\lambda}(Vega)\lambda\textrm{d}\lambda}
\end{equation*}
(as above, the factor of $\lambda$ comes in for photon counting
detectors). This gives the magnitude in U, B, V, R, \emph{or} I,
by integrating over that same bandpass.
The UBVRI filter set had overlapping bandpasses, so
there was a switch to interference filter: the ugriz system used
by SDSS (explained below... I think).\\

\noindent Here is a
\href{http://astronomy.nmsu.edu/holtz/a535/html/diagrams/a535/mag.htm}
{\textcolor{blue}{plot}}
to demonstrate the difference between the different systems.\\

\noindent While it seems that STMAG and ABNU systems are more
straightforward, in practice it is difficult to measure absolute
fluxes, and much easier to measure relative fluxes between objects.
Hence, historically observations were tied to observations of Vega (or
to stars which themselves were tied to Vega), so VEGAMAGs made sense,
and the issue of determining physical fluxes boiled down to measuring
the physical flux of Vega. Today, in some cases, it may be more
accurate to measure the absolute throughput of an instrumental system,
and using STMAG or ABNU makes more sense.

\subsubsection*{Colors}
Working in magnitudes, the difference in magnitudes between different
bandpasses (called the color index, or simply, color) is related to
the flux ratio between the bandpasses, i.e., the color.
In the UBVRI
system, the \emph{difference between magnitudes}, e.g. B-V,
gives the ratio of the fluxes in different bandpasses
\emph{relative to the ratio of the fluxes of
an A0V star in the different bandpasses (for VEGAMAG)}.
Note the typical colors of astronomical objects,
which are different for the different photometric systems.
Type `A' stars have color 0, and have the same SED as Vega.
Type `O' stars have color less than 0,
while cooler stars have color greater than 0.
In sloan system, have  g-r (ugriz). g-r=0 indicates constant
$F_{\nu}$.
\begin{equation*}
    m = -2.5\log\frac{\int_B F_{\lambda}\textrm{d}\lambda}
    {\int_V F_{\lambda}\textrm{d}\lambda}
\end{equation*}
if B-V=0, then (B/V)$_{object}$ is the same as (B/V)$_{Vega}$,
or $\Big(\frac{\int F_{\nu}}{\int F_{\lambda}}\Big)_{obj} = 
    \Big(\frac{\int F_{\nu}}{\int F_{\lambda}}\Big)_{Vega} $.

What would the flux be from an object with some magnitude,
x? Need this to know how much observing time I need. E.g., convert the
spectrum of an elliptical galaxy to color; if you know F in one
filter, you can get F in another filter.

Which is closer to the UBVRI system, STMAG or ABNU?

What would typical colors be in a STMAG or ABNU system?

\textcolor{magenta}{Wednesday, January 27}

\subsubsection*{UBVRI magnitudes-flux conversion
}
To \textcolor{red}{convert Vega-based magnitudes to fluxes},
look up the flux of Vega at the center of the passband;
however, if the spectrum of the object
differs from that of Vega, this won't be perfectly accurate.
Given UBVRI magnitudes of an object in the desired band, filter profiles
(e.g. Bessell 1990, PASP 102,1181), and absolute spectrophotometry of
Vega (e.g., \href{http://adsabs.harvard.edu/abs/2004AJ....127.3508B}
{\textcolor{blue}{Bohlin \& Gilliland 2004, AJ 127, 3508}},
one can determine the flux.

If one wanted to estimate the flux of some object in
arbitrary bandpass given just the V magnitude of an object (a common
situation used when trying to predict exposures times, see below),
this can be done if an estimate of the spectral energy distribution
(SED) can be made; given the filter profiles, one can compute the
integral of the SED over the V bandpass, determine the scaling by
comparing with the integral of the Vega spectrum over the same
bandpass, then use the normalized SED to compute the flux in any
desired bandpass. Some possibly useful references for SEDs are:
Bruzual, Persson, Gunn, \& Stryker; Hunter, Christian, \& Jacoby;
Kurucz).

Things are certainly simpler in the ABNU or STMAG system, and
there has been some movement in this direction: the STScI gives STMAG
calibrations for HST instruments, and the SDSS photometric system is
close to an ABNU system.

Note, however, that even when the systems are conceptually
well defined, determining the absolute calibration of any photometric
system is very difficult in reality, and determining absolute fluxes
to the 1\% level is very challenging.

As a separate note on magnitudes themselves, note that some
people, in particular, the SDSS, have adopted a modified type of
magnitudes, called asinh magnitudes, which behave like normal (also
known as Pogson) magnitude for brighter objects, but have different
behavior for very faint objects (near the detection threshold); see
\href{http://adsabs.harvard.edu/abs/1999AJ....118.1406L}
{\textcolor{blue}{Lupton, Gunn, \& Szalay 1999 AJ 118, 1406}}
for details.

%---------------------------------------------------------------%

\subsection*{Observed fluxes and the count equation}
What if you are measuring flux with an actual instrument, i.e.\
counting photons? The intrinsic photon flux from the source is not
trivial to determine from the number of photons that you count. To get
the number of photons that you count in an observation, you need to
take into account
\begin{itemize}
    \item The area of your photon collector (telescope)
    \item Photon losses and gains from the Earth's atmosphere
    (which change with conditions)
    \item The efficiency of your collection/detection
    apparatus (which can change with time).
\end{itemize}
Generally, the astronomical signal (which might be a flux or a
surface brightness, depending on whether the object is resolved)
can be written in the form of the \emph{\textbf{count equation:}}
    $$ S = Tt \int \frac{F_{\lambda}}{\frac{hc}{\lambda}}q_{\lambda}
    a_{\lambda}\textrm{d}\lambda \equiv TtS' $$
    \begin{itemize}
        \item $S$: total number of photons observed (the ``signal")
        \item $S'$ is an observed flux rate,
        i.e. with all of the real details of the observing system included.
        \item $a_{\lambda}$: atmospheric transmission,
        or \emph{throughput}, which is the fraction of photons that
        make it through.
        (a typical value is about 0.9; $\sim$90\% of photons)
        \item $q_{\lambda}$ is the system efficiency
        (which includes telescope, filters, optics, detector, etc.),
        \item $T$: telescope collecting area
        \item $t$ is the integration time
        (total amount of time spent collecting photons).
        \item $F_{\lambda}/\frac{hc}{\lambda}$:
        flux divided by the energy per photon;
        gives the number of photons per second per square cm.
    \end{itemize}
$T$ and $t$ are the \emph{only} terms that do not depend on
the wavelength (or frequency).

Usually, however, one doesn't use this information to go
backward from $S$ to $F_{\lambda}$ because it is very
difficult to measure all of the terms precisely, and some of them
(e.g. $a$, and perhaps $q$) are time-variable; $a$ is also spatially
variable. Instead, most observations are performed differentially to a
set of other stars of well known brightness. If the stars of known
brightness are observed in the same observation, then the atmospheric
term is (approximately) the same for all stars; this is known as
\emph{differential photometry}.
From the photon flux of the object with known
brightness, one could determine an ``exposure efficiency''
or an ``effective area'' for this
exposure. Equivalently, and more commonly, one can calculate an
\emph{instrumental magnitude}:
    $$  m = -2.5 \log \frac{S}{t} $$
(i.e., normalize by the exposure time to get counts/sec, although this
is not strictly necessary) and then determine the \emph{zeropoint},
$z$, that needs
to be added to give the calibrated magnitude, $M$
(which is still an \emph{apparent} magnitude).
    $$ M = m + z $$
Note that in the real world, one has to also consider possible
differences between a given experimental setup and the setup used to
measure the reference brightnesses, so this is only a first
approximation (i.e., the zeropoint may be different for different
stars with different spectral properties)! If using instrumental mags
including exposure time normalization, the zeropoint gives the
magnitude of a star that will give 1 count/second.

\textcolor{magenta}{FOV: usually in arcminute scales.
To go from observed to emitted $\rightarrow$ 2 different observations
(know flux of one: SDSS has list of stars with known brightness).
A star that is 10 times fainter than one with g=18 has g=20.5.
}

If there are no stars of known brightness in the same
observation, then calibration must be done against stars in other
observations. This then requires that the different effects of the
Earth's atmosphere in different locations in the sky be accounted for.
This is known as \emph{all-sky}, or absolute, photometry. To do this requires
that the sky is ``well-behaved", i.e. one can accurately predict the
atmospheric throughput as a function of position. This requires that
there be no clouds, i.e. \emph{photometric} weather. Differential photometry
can be done in non-photometric weather, hence it is much simpler. Of
course, it is always possible to obtain differential photometry and
then go back later and obtain absolute photometry of the reference
stars.

Of course, at some point, someone needs to figure out what
the fluxes of the calibrating stars really are, and this requires
understanding all of the terms in the count equation. It is
challenging, and often, absolute calibration of a system is uncertain
to a couple of percent.

It is also common to stop with differential photometry if
one is studying variable objects, i.e. where one is just interested in
the change in brightness of an object, not the absolute flux level. In
this case, one only has to reference the brightness of the target
object relative some other object (or ensemble of objects) in the
field that are non-variable.

While the count equation isn't usually used for calibration,
it is very commonly used for computing the approximate number of
photons you will receive from a given source in a given amount of time
for a given observational setup. This number is critical to know in
order to estimate your expected errors and exposure times in observing
proposals, observing runs, etc. Understanding errors in absolutely
critical in all sciences, and maybe even more so in astronomy, where
objects are faint, photons are scarce, and errors are not at all
insignificant. The count equation provides the basis for exposure time
calculator (ETC) programs, because it gives an expectation of the
number of photons that will be received by a given instrument as a
function of exposure time. As we will see shortly, this provides the
information we need to calculate the uncertainty in the measurement as
a function of exposure time.

%-----------------------------------------------------------------------%

\subsection*{Uncertainties in photon rates}
For a given rate of emitted photons, there's a probability function
which gives the number of photons we detect, even assuming 100\%
detection efficiency, because of \emph{statistical} uncertainties. In
addition, there may also be \emph{instrumental} uncertainties. Consequently,
we now turn to the concepts of probability distributions, with
particular interest in the distribution which applies to the detection
of photons.

\emph{Distributions and characteristics thereof}
\begin{itemize}
    \item concept of a distribution: define $p(x)dx$ as probability of
    event occuring in $x + \textrm{d}x$:
        $$ \int p(x)\textrm{d}x = 1 $$
\end{itemize}
Some definitions relating to values which characterize a distribution:
\begin{align*}
    mean \equiv \mu &= \int xp(x)\textrm{d}x \\
    variance \equiv \sigma^2 &= \int (x-\mu)^2 p(x)\textrm{d}x \\
    standard\ deviation \equiv \sigma &= \sqrt{\textrm{variance}}
\end{align*}
median: mid-point value.
\begin{align*}
    \frac{ \int_{-\infty}^{x_{median}} p(x)\textrm{d}x }
    { \int_{-\infty}^{\infty} p(x)\textrm{d}x }
    &= \frac{1}{2}
\end{align*}
mode: most probable value (peak in plot).

\textcolor{magenta}{Monday, February 1}

Note that the geometric interpretation of above quantities
depends on the nature of the distribution; although we all carry
around the picture of the mean and the variance for a Gaussian
distribution, these pictures are not applicable to other
distributions, but the quantities are still well-defined.

Also, note that there is a difference between the
\emph{sample}
mean, variance, etc. and the \emph{population} quantities. The latter apply
to the true distribution, while the former are estimates of the latter
from some finite sample ($N$ measurements) of the population. The sample
quantities are derived from:
$$\textrm{sample\ mean:\ } \bar{x} \equiv \frac{\sum x_i}{N}$$
$$\textrm{sample\ variance:\ } \equiv
  \frac{\sum (x_i-\bar{x})^2}{N-1} =
  \frac{\sum x_i^2-(\sum x_i)^2/N}{N-1}$$
The sample mean and variance approach the true mean and variance as N
approaches infinity. But note, especially for small samples, your
estimate of the mean and variance may differ from their true
(population) values (more below).

Now we consider what distribution is appropriate for the
detection of photons. The photon distribution can be derived from the
\emph{binomial} distribution, which gives the probability of observing the
number, $x$, of some possible event, given a total number of events $n$,
and the probability of observing the particular event (among all other
possibilities) in any single event, $p$, under the assumption that all
events are independent of each other:
   $$ P(x,n,p) = \frac{n!p^x(1-p)^{n-x}}{x!(n-x)!}  $$
For the binomial distribution, one can derive:
   $$ \textrm{mean} \equiv \int xp(x)\textrm{d}x = np $$
   $$ \textrm{variance} \equiv \sigma^2 \equiv
      \int (x-\mu)^2p(x)\textrm{d}x = np(1-p) $$
\emph{The Poisson distribution}

In the case of detecting photons, $n$ is the total number of
photons emitted, and $p$ is the probability of detecting a photon during
our observation out of the total emitted. We don't know either of
these numbers. However, we do know that p$<<$1 and we know, or at
least we can estimate, the mean number detected:
  $$  \mu = np $$
In this limit, the binomial distribution asymtotically approaches the
\emph{Poisson} distribution:
   $$  P(x,\mu) = \frac{\mu^x e^{-\mu}}{x!} $$
From the expressions for the binomial distribution in this limit, the
mean of the distribution is $\mu$, and the variance is
  $$  \textrm{variance} = \sum_x [(x-\mu)^2p(x,\mu)] $$
  $$  \textrm{variance} = np = \mu  $$
This is an \emph{important result}.

Note that the Poisson distribution is generally the
appropriate distribution not only for counting photons, but for
\emph{any} sort of counting experiment where a series of events
occurs with a known average rate, and are independent of time
since the last event.\\

\noindent What does the Poisson distribution look like?
\href{http://astronomy.nmsu.edu/holtz/a535/html/diagrams/a535/poisson.htm}
{\textcolor{blue}{Plots}}
for $\mu$ = 2, $\mu$ = 10, $\mu$ = 10000.\\

\noindent \emph{The normal, or Gaussian, distribution}\\

\noindent Note, for large $\mu$, the Poisson distribution is
well-approximated around the peak by a \emph{Gaussian}, or
\emph{normal} distribution:
    $$ P(x,\mu,\sigma) = \frac{1}{\sigma\sqrt{2\pi}}
        e^{ -\frac{1}{2} (\frac{x-\mu}{\sigma})^2 }  $$
This is important because it allows us to use ``simple'' least squares
techniques to fit observational data, because these generally assume
normally distributed data. However, beware that in the tails of the
distribution, and at low mean rates, the Poisson distribution can
differ significantly from a Gaussian distribution. In these cases,
least-squares may not be appropriate to model observational data;
instead, one might need to consider maximum likelihood techniques
instead.\\

\noindent The normal distribution is also important because many
physical variables seem to be distributed accordingly. This may not be
an accident because of the \emph{central limit theorem}: if a quantity
depends on a number of independent random variables with ANY
distribution, the quantity itself will be distributed normally (see
statistics texts). In observations, we encounter the normal
distribution because one important source of \emph{instrumental noise},
readout noise, is distributed normally.\\

\noindent \emph{Importance of error distribution analysis}\\

\noindent You need to understand the expected uncertainties in your
observations in order to:
\begin{itemize}
    \item predict the amount of observing time you'll need to get
    uncertainties as small as you need them to do your science
    \item answer the question: is scatter in observed data consistent
    with expected uncertainties? If the answer is no, they you know
    you've either learned some astrophysics or you don't understand
    something about your observations. This is especially important in
    astronomy where objects are faint and many projects are pushing
    down into the noise as far as possible. Really we can usually only
    answer this probabilistically. Generally, tests compute the
    probability that the observations are consistent with an expected
    distribution (the null hypothesis). You can then look to see if
    this probability is low, and if so, you can reject the null
    hypothesis.
    \item interpret your results in the context of a scientific
    prediction
\end{itemize}
\emph{Confidence levels}\\

\noindent For example, say we want to know whether some single point
is consistent with expectations, e.g., we see a bright point in
multiple measurements of a star, and want to know whether the star
flared. Say we have a time sequence with known mean and variance, and
we obtain a new point, and want to know whether it is consistent with
known distribution?\\

\noindent If the form of the probability distribution is known, then
you can calculate the probability of getting a measurement more than
some observed distance from the mean. In the case where the observed
distribution is Gaussian (or approximately so), this is done using the
\emph{error function} (sometimes called $erf(x)$), which is the integral of a
gaussian from some starting value.\\

\noindent Some simple guidelines to keep in mind follow (the actual
situation often requires more sophisticated statistical tests). First,
for Gaussian distributions, you can calculate that 68\% of the points
should fall within $\pm 1\sigma$ from the mean, and 95.3\%
should fall within $\pm 2\sigma$ from the mean. Thus, if you have a
time line of photon fluxes for a star, with $N$ observed points, and a
photon noise $\sigma$ on each measurement, you can test whether the
number of points deviating more than 2$\sigma$ from the mean is much
larger than expected. To decide whether any single point is really
significantly different, you might want to use more stringent
criterion, e.g., 5$\sigma$ rather than a 2$\sigma$ criterion;
a 5$\sigma$ has much higher level of significance. On the other hand, if
you have far more points in the range $2-4\sigma$ brighter or
fainter than you would expect, you may also have a significant
detection of intensity variations (provided you really understand your
uncertainties on the measurements).

Also, note that your observed distribution should be
consistent with your uncertainty estimates given the above guidelines.
If you have a whole set of points, that all fall within 1$\sigma$ of
each other, something is wrong with your uncertainty estimates (or
perhaps your measurements are correlated with each other).

For a series of measurements, one can calculate the
$\chi^{2}$ statistic, and determine how probable this value is,
given the number of points.
    $$ \chi^2 = \sum [(observed(i)-model(i))^2/\sigma_i^2]  $$
A quick estimate of the consistency of the model with the observed
data points can be made using reduced $\chi^{2}$, defined as
$\chi^{2}$ divided by the \emph{degrees of freedom} (number of data points
minus number of parameters).

\textcolor{magenta}{Wednesday, February 3}

\subsubsection*{Noise equation: how do we predict expected
uncertainties?}
\emph{Signal-to-noise}

Astronomers often describe uncertainties in terms of the fractional
error, e.g. the amplitude of the uncertainty divided by the amplitude
of the quantity being measured; often, the inverse of this, referred
to as the signal-to-noise ratio, is used. Given an estimate the number
of photons expected from an object in an observation, we can calulate
the signal-to-noise ratio:
    $$ \frac{S}{N} = \frac{S}{\sqrt{\sigma^2}} $$
which is the inverse of the predicted fractional error ($N/S$).

Consider an object with observed photon flux (per unit area and time,
e.g. from the count equation above), S$^{\prime}$, leading
to a signal, S = S$^{\prime}$Tt where T is the telescope
area and t is the exposure time. In the simplest case (i.e. perfect
instruments), the only noise
source is Poisson statistics from the source, in which case:
    $$ \sigma^2 = S = S^{\prime}Tt $$
    $$ \frac{S}{N} = \sqrt{S} = \sqrt{S^{\prime}Tt} $$
In other words, $S/N$ increases as the square root of the object
brightness, telescope area, efficiency, or exposure time. Note that $S$
is directly observable, so one can calculate $S/N$ for an
observation without knowing the telescope area or exposure time.
We've just broken $S$ down so that you can specifically see the dependence on
telescope area and/or exposure time.

\emph{Background noise}

A more realistic case includes the noise contributed from Poisson
statistics of ``background'' light, $B^{\prime}$,
which has units of flux per area
on the sky (i.e. a surface brightness); note that this is also usually
given in magnitudes (more on the physical nature of
this later).

    $$ B^{\prime} = \int \frac{B_{\lambda}}{\frac{hc}{\lambda}}
       q_{\lambda}\textrm{d}\lambda $$

The amount of background in our measurement depends on how we choose
to make the measurement (how much sky area we observe). Say we just
use an aperture with area, $A$, so the total observed background counts
is
    $$ AB = AB^{\prime}Tt $$

Again, $B^{\prime}Tt$ is the directly observable quantity,
but we split it into the quantities on which it depends to understand
what factors are important in determining $S/N$.

The total number of photons observed, $O$, is
    $$ O = S + AB = (S^{\prime} + AB^{\prime})Tt $$
The variance of the total observed counts, from Poisson statistics,
is:
    $$ \sigma^2_O = O =  S + AB = (S^{\prime} + AB^{\prime})Tt $$
To get the desired signal from the object only, we will need to
measure separately the total signal and the background signal to
estimate:
    $$ S \equiv S^{\prime}Tt = O-A <B> $$
where $<B>$ is some estimate we have obtained of the background
surface brightness. The noise in the measurement is
    $$ \sigma^2_S \approx \sigma^2_O =
    S + AB = (S^{\prime} + AB^{\prime})Tt $$
where the approximation is accurate if the background is determined to
high accuracy, which one can do if one measures the background over a
large area, thus getting a large number of background counts (with
correspondingly small fractional error in the measurement).

This leads to a common form of the \emph{noise equation}:
    $$ \frac{S}{N} = \frac{S}{\sqrt{S+AB}}  $$
Breaking out the dependence on exposure time and telescope area, this
is:
    $$ \frac{S}{N} = \frac{S^{\prime}}
    {\sqrt{S^{\prime}+AB^{\prime}}}
    \sqrt{T}\sqrt{t}$$

In the \emph{signal-limited} case, $S^{\prime}\gg B^{\prime}A$,
we get
$$ \frac{S}{N} = \sqrt{S} = \sqrt{S^{\prime}tT} $$
In the \emph{background-limited} case, $B^{\prime}A\gg S^{\prime}$,
and
$$ \frac{S}{N} = \frac{S}{\sqrt{B}} =
   \frac{S^{\prime}}{\sqrt{B^{\prime}A}}\sqrt{tT} $$

As one goes to fainter objects, the S/N drops, and it drops faster
when you're background limited. This illustrates the importance of
dark-sky sites, and also the importance of good image quality.

Consider two telescopes of collecting area, $T_1$ and $T_2$.
If we observe for the same exposure time on each and want to know how
much fainter we can see with the larger telescope at a given $S/N$, we
find this for a signal-limited case:
$$ S_2 = \frac{T_1}{T_2}S_1 $$
but find \emph{this} for the background-limited case:
$$ S_2 = \sqrt{\frac{T_1}{T_2}}S_1  $$

\emph{Instrumental noise}

In addition to the errors from Poisson statistics (statistical noise),
there may be additional terms from instrumental errors. A common
example of this that is applicable for CCD detectors is readout noise,
which is additive \emph{noise} (with zero mean) that comes from the detector
and is independent of signal level. For a detector whose readout noise
is characterized by $\sigma_{rn}$,
$$ \frac{S}{N} = \frac{S}{\sqrt{S+BA_{pix}+\sigma^2_{rn}}} $$
if a measurement is made in a single pixel. If an object is spread
over $N_{pix}$ pixels, then
$$ \frac{S}{N} = \frac{S}{\sqrt{S+BA+N_{pix}\sigma^2_{rn}}} $$
For large $\sigma_{rn}$, the behavior is the same as the
background-limited case. This makes it clear that if you have readout
noise, image quality (and/or proper optics to keep an object from
covering too many pixels) is important for maximizing $S/N$. It is
also clear that it is critical to have minimum read-noise for low
background applications (e.g., spectroscopy).

There are other possible additional terms in the noise equation,
arising from things like dark current, digitization noise, errors in
sky determination, errors from photometric technique, etc. (we'll
discuss some of these later on), but in most applications, the three
sources discussed so far - signal noise, background noise, and readout
noise - are the dominant noise sources.

Note the applications where one is likely to be signal dominated,
background dominated, and readout noise dominated.

\textcolor{magenta}{Monday, February 8}

\subsubsection*{Error propagation}
\subsubsection*{Determining sample parameters: averaging measurements}
\subsubsection*{Random errors vs systematic errors}

\end{document}































